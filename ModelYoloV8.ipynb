{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-413UBpJP9b5"
      },
      "source": [
        "# Global Configs"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xsNmWeu2hDyg"
      },
      "source": [
        "# Drive"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cuW1xibxhIZc",
        "outputId": "d8a90db4-83b4-4abd-b30d-9867ef49b136"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n8fvSVURhafl"
      },
      "source": [
        "#config"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_vdvxAkThZ_2",
        "outputId": "9c51db9e-0b1b-4b6b-a6bb-26c61ad7b1f7"
      },
      "outputs": [],
      "source": [
        "# Imports\n",
        "from pathlib import Path\n",
        "import torch\n",
        "import os\n",
        "\n",
        "# Global Paths\n",
        "ROOT_DIR  = Path(\"/content/drive/MyDrive/Pós-Graduações/Computer_Vision_Master/Materias/DOIV/trabalho_final\")\n",
        "\n",
        "# Yolov8 paths\n",
        "DATASET_DIR_YOLO = ROOT_DIR / \"dataset_marinedebris_yolov8\"\n",
        "DATASET_YAML = DATASET_DIR_YOLO / \"data.yaml\"\n",
        "# Models\n",
        "MODEL_NAME_YOLO = \"yolov8n.pt\"\n",
        "MODEL_NAME_YOLO_FINAL1 = ROOT_DIR / \"yolov8n_marinedebris_best_final_1.pt\"\n",
        "WEIGHTS_YOLOV8_BASELINE = ROOT_DIR / \"yolov8n_marinedebris_baseline.pt\"\n",
        "WEIGHTS_YOLOV8_BASELINE_ADJUSTED = ROOT_DIR / \"yolov8n_marinedebris_baseline_adjusted.pt\"\n",
        "WEIGHTS_YOLOV8_BEST = ROOT_DIR / \"yolov8n_marinedebris_best_final.pt\"\n",
        "# Final Model Names\n",
        "MODEL_NAME_YOLO_FINAL_TUNNED = \"yolov8n_marinedebris_best_final_2.pt\"\n",
        "MODEL_NAME_YOLO_FINAL_PARAMS = ROOT_DIR / \"best_params_used_final_model_2.csv\"\n",
        "MODEL_NAME_YOLO_FINAL_BASELINE_TUNNED = \"yolov8n_marinedebris_best_baseline_tunned.pt\"  # Best model\n",
        "MODEL_NAME_YOLO_FINAL_BASELINE_PARAMS = ROOT_DIR / \"best_params_used_baseline_tunned.csv\"\n",
        "# Optmizer\n",
        "OPTIMIZER_RESULTS = ROOT_DIR / \"optuna_results.csv\"\n",
        "\n",
        "# Config Device\n",
        "DEVICE = (\n",
        "          \"cuda\"\n",
        "          if torch.cuda.is_available()\n",
        "          else \"mps\"\n",
        "          if torch.backends.mps.is_available()\n",
        "          else \"cpu\"\n",
        "          )\n",
        "\n",
        "print(f\"GPU is available? {torch.cuda.is_available()}\")\n",
        "\n",
        "print(f\"Using {DEVICE} device\")\n",
        "\n",
        "# InferenceTest Prediction\n",
        "TEST_IMAGE1 = ROOT_DIR / \"test_image_marinedebris1.jpg\"\n",
        "TEST_IMAGE2 = ROOT_DIR / \"test_image_marinedebris2.jpg\"\n",
        "TEST_IMAGE3 = ROOT_DIR / \"test_image_marinedebris3.jpg\"\n",
        "TEST_IMAGE4 = ROOT_DIR / \"test_image_marinedebris4.jpg\"\n",
        "TEST_IMAGE5 = ROOT_DIR / \"test_image_marinedebris5.png\"\n",
        "TEST_IMAGE6 = ROOT_DIR / \"test_image_marinedebris6.png\"\n",
        "TEST_VIDEO = ROOT_DIR / \"marine-debris-polution.mp4\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0GCMZKUwtHEu"
      },
      "outputs": [],
      "source": [
        "# # RUN ONLY FOR CLEANING THE MEMORY\n",
        "# # Cleaning GPU memory\n",
        "# import numba\n",
        "# from numba import cuda\n",
        "\n",
        "# device = cuda.get_current_device()\n",
        "# device.reset()\n",
        "\n",
        "# # CPU\n",
        "# import gc\n",
        "# gc.collect()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "abGsZLHukcET"
      },
      "source": [
        "# Pre Processing Datasets"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YqhCBWk8yu_3"
      },
      "source": [
        "## preprocessing_module"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UHJB0Rb4kvTA"
      },
      "outputs": [],
      "source": [
        "# imports\n",
        "from pathlib import Path\n",
        "from collections import Counter, defaultdict\n",
        "import yaml\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import random\n",
        "\n",
        "# Classes\n",
        "class PreProcessorYoloV8:\n",
        "    \"\"\"\n",
        "    Utility class for inspecting and visualizing YOLOv8 datasets.\n",
        "\n",
        "    This class provides tools to:\n",
        "    - Load class definitions from a YOLO data.yaml file\n",
        "    - Count object instances per class and dataset split\n",
        "    - Visualize class distribution across splits\n",
        "    - Plot example images with YOLO bounding box annotations\n",
        "\n",
        "    It assumes a standard YOLO directory structure:\n",
        "    data_path/\n",
        "        train/\n",
        "            images/\n",
        "            labels/\n",
        "        valid/\n",
        "            images/\n",
        "            labels/\n",
        "        test/\n",
        "            images/\n",
        "            labels/\n",
        "    \"\"\"\n",
        "    def __init__(self, model_name, data_path, yaml_path):\n",
        "        \"\"\"\n",
        "        Initialize the YOLOv8 dataset preprocessor.\n",
        "\n",
        "        Parameters\n",
        "        ----------\n",
        "        model_name : str\n",
        "            Name or identifier of the YOLO model (e.g., 'yolov8n', 'yolov8m').\n",
        "            Stored for reference and logging purposes.\n",
        "        data_path : pathlib.Path\n",
        "            Root directory of the YOLO dataset.\n",
        "        yaml_path : pathlib.Path\n",
        "            Path to the YOLO data.yaml file containing class definitions.\n",
        "        \"\"\"\n",
        "\n",
        "        self.model_name = model_name\n",
        "        self.data_path = data_path\n",
        "        self.yaml_path = yaml_path\n",
        "        self.class_map = self._load_classes()  # for yolov8\n",
        "        self.results = None\n",
        "\n",
        "\n",
        "    def _load_classes(self) -> dict:\n",
        "        \"\"\"\n",
        "        Load class names from the YOLO data.yaml file.\n",
        "\n",
        "        Returns\n",
        "        -------\n",
        "        dict\n",
        "            Mapping from class index (int) to class name (str).\n",
        "\n",
        "        Raises\n",
        "        ------\n",
        "        TypeError\n",
        "            If the 'names' field in the YAML file is not a list.\n",
        "        \"\"\"\n",
        "\n",
        "        with open(self.yaml_path, \"r\") as f:\n",
        "            data = yaml.safe_load(f)\n",
        "\n",
        "        names = data[\"names\"]\n",
        "\n",
        "        if isinstance(names, list):\n",
        "            return {i: name for i, name in enumerate(names)}\n",
        "\n",
        "        raise TypeError(\"Formato inválido para 'names' no data.yaml\")\n",
        "\n",
        "    def _count_split(self, split: str) -> Counter:\n",
        "        \"\"\"\n",
        "        Count object instances per class for a given dataset split.\n",
        "\n",
        "        Parameters\n",
        "        ----------\n",
        "        split : str\n",
        "            Dataset split name ('train', 'valid', or 'test').\n",
        "\n",
        "        Returns\n",
        "        -------\n",
        "        collections.Counter\n",
        "            Counter mapping class_id (int) to number of objects.\n",
        "        \"\"\"\n",
        "\n",
        "        labels_path = self.data_path / split / \"labels\"\n",
        "        counter = Counter()\n",
        "\n",
        "        for label_file in labels_path.glob(\"*.txt\"):\n",
        "            with open(label_file) as f:\n",
        "                for line in f:\n",
        "                    class_id = int(line.split()[0])\n",
        "                    counter[class_id] += 1\n",
        "\n",
        "        return counter\n",
        "\n",
        "\n",
        "    def count_all(self) -> dict:\n",
        "        \"\"\"\n",
        "        Count object instances per class for all dataset splits.\n",
        "\n",
        "        The results are stored internally and returned as a dictionary\n",
        "        indexed by split name and class name.\n",
        "\n",
        "        Returns\n",
        "        -------\n",
        "        dict\n",
        "            Nested dictionary of the form:\n",
        "            {\n",
        "                'train': {'class_name': count, ...},\n",
        "                'valid': {'class_name': count, ...},\n",
        "                'test':  {'class_name': count, ...}\n",
        "            }\n",
        "        \"\"\"\n",
        "\n",
        "        self.results = {}\n",
        "\n",
        "        for split in [\"train\", \"valid\", \"test\"]:\n",
        "            split_counter = self._count_split(split)\n",
        "\n",
        "            self.results[split] = {\n",
        "                                    self.class_map[class_id]: count\n",
        "                                    for class_id, count in split_counter.items()\n",
        "                                    }\n",
        "\n",
        "        return self.results\n",
        "\n",
        "\n",
        "    def _autolabel(self, bars, values, total):\n",
        "        \"\"\"\n",
        "        Attach percentage labels above bar plots.\n",
        "\n",
        "        Parameters\n",
        "        ----------\n",
        "        bars : matplotlib.container.BarContainer\n",
        "            Bars returned by matplotlib's bar() function.\n",
        "        values : iterable\n",
        "            Numerical values corresponding to each bar.\n",
        "        total : float\n",
        "            Total value used to compute percentages.\n",
        "        \"\"\"\n",
        "\n",
        "        for bar, v in zip(bars, values):\n",
        "            if v == 0:\n",
        "                continue\n",
        "\n",
        "            pct = 100 * v / total\n",
        "\n",
        "            plt.text(\n",
        "                     bar.get_x() + bar.get_width() / 2,\n",
        "                     bar.get_height(),\n",
        "                     f\"{pct:.1f}%\",\n",
        "                     ha=\"center\",\n",
        "                     va=\"bottom\",\n",
        "                     fontsize=8\n",
        "                     )\n",
        "\n",
        "\n",
        "    def classes_show(self):\n",
        "        \"\"\"\n",
        "        Plot class distribution per dataset split.\n",
        "\n",
        "        Displays a grouped bar chart showing the number and percentage\n",
        "        of objects per class for train, validation, and test splits.\n",
        "\n",
        "        Raises\n",
        "        ------\n",
        "        RuntimeError\n",
        "            If count_all() has not been executed beforehand.\n",
        "        \"\"\"\n",
        "\n",
        "        if self.results is None:\n",
        "            raise RuntimeError(\"Execute count_all() antes de chamar classes_show().\")\n",
        "\n",
        "        df = pd.DataFrame(self.results).fillna(0)\n",
        "\n",
        "        classes = df.index\n",
        "        x = np.arange(len(classes))\n",
        "        width = 0.25\n",
        "        totals = df.sum(axis=0)\n",
        "\n",
        "        # Plot\n",
        "        plt.figure(figsize=(10, 5))\n",
        "\n",
        "        bars_train = plt.bar(x - width, df[\"train\"], width, label=\"Train\")\n",
        "        bars_val   = plt.bar(x,         df[\"valid\"], width, label=\"Val\")\n",
        "        bars_test  = plt.bar(x + width, df[\"test\"],  width, label=\"Test\")\n",
        "\n",
        "        self._autolabel(bars_train, df[\"train\"], totals[\"train\"])\n",
        "        self._autolabel(bars_val,   df[\"valid\"], totals[\"valid\"])\n",
        "        self._autolabel(bars_test,  df[\"test\"],  totals[\"test\"])\n",
        "\n",
        "        plt.xticks(x, classes, rotation=45)  # type: ignore\n",
        "        plt.ylabel(\"Number of objects\")\n",
        "        plt.title(\"YOLO class distribution (%) per split\")\n",
        "        plt.legend()\n",
        "        plt.tight_layout()\n",
        "        plt.show()\n",
        "\n",
        "\n",
        "    def plot_class_examples(self, split: str = \"train\"):\n",
        "        \"\"\"\n",
        "        Plot one example image per class with YOLO bounding boxes.\n",
        "\n",
        "        For each class, a random labeled image is selected and all\n",
        "        bounding boxes are drawn. The target class is highlighted.\n",
        "\n",
        "        Parameters\n",
        "        ----------\n",
        "        split : str, optional\n",
        "            Dataset split to visualize ('train', 'valid', or 'test'),\n",
        "            by default 'train'.\n",
        "        \"\"\"\n",
        "\n",
        "        images_path = self.data_path / split / \"images\"\n",
        "        labels_path = self.data_path / split / \"labels\"\n",
        "\n",
        "        # Map: class_id -> label file\n",
        "        class_examples = {}\n",
        "\n",
        "        # Find one image per class\n",
        "        for label_file in labels_path.glob(\"*.txt\"):\n",
        "            with open(label_file) as f:\n",
        "                lines = f.readlines()\n",
        "\n",
        "            for line in lines:\n",
        "                class_id = int(line.split()[0])\n",
        "\n",
        "                class_examples.setdefault(class_id, []).append(label_file)\n",
        "\n",
        "        class_examples = {\n",
        "                          cid: random.choice(files)\n",
        "                          for cid, files in class_examples.items()\n",
        "                         }\n",
        "\n",
        "        n_classes = len(class_examples)\n",
        "        ncols = min(4, n_classes)\n",
        "        nrows = int(np.ceil(n_classes / ncols))\n",
        "\n",
        "        fig, axes = plt.subplots(nrows, ncols, figsize=(4 * ncols, 4 * nrows))\n",
        "        axes = np.array(axes).reshape(-1)\n",
        "\n",
        "        for ax, (class_id, label_file) in zip(axes, class_examples.items()):\n",
        "            image_file = images_path / (label_file.stem + \".jpg\")\n",
        "\n",
        "            if not image_file.exists():\n",
        "                image_file = images_path / (label_file.stem + \".png\")\n",
        "\n",
        "            img = plt.imread(image_file)\n",
        "            h, w = img.shape[:2]\n",
        "\n",
        "            ax.imshow(img)\n",
        "            ax.axis(\"off\")\n",
        "\n",
        "            with open(label_file) as f:\n",
        "                for line in f:\n",
        "                    cid, xc, yc, bw, bh = map(float, line.split())\n",
        "\n",
        "                    # YOLO → pixel coords\n",
        "                    xmin = (xc - bw / 2) * w\n",
        "                    ymin = (yc - bh / 2) * h\n",
        "                    xmax = (xc + bw / 2) * w\n",
        "                    ymax = (yc + bh / 2) * h\n",
        "\n",
        "                    color = \"blue\" if int(cid) == class_id else \"lime\"\n",
        "\n",
        "                    rect = plt.Rectangle(              # type: ignore\n",
        "                                         (xmin, ymin),\n",
        "                                         xmax - xmin,\n",
        "                                         ymax - ymin,\n",
        "                                         fill=False,\n",
        "                                         color=color,\n",
        "                                         linewidth=2\n",
        "                                         )\n",
        "                    ax.add_patch(rect)\n",
        "\n",
        "            class_name = self.class_map[class_id]\n",
        "            ax.set_title(class_name, fontsize=12, color=\"blue\")\n",
        "\n",
        "        # Remove empty axes\n",
        "        for ax in axes[len(class_examples):]:\n",
        "            ax.axis(\"off\")\n",
        "\n",
        "        plt.tight_layout()\n",
        "        plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kbqhD1Ar2Hd5"
      },
      "source": [
        "## Preprocessor Main"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G-YJf2Ys2J6a",
        "outputId": "aeefcc4e-0a4d-4d67-a510-3b7a12d8377d"
      },
      "outputs": [],
      "source": [
        "def main():\n",
        "    prep = PreProcessorYoloV8(\n",
        "                              model_name=\"yolov8\",\n",
        "                              data_path=DATASET_DIR_YOLO,\n",
        "                              yaml_path=DATASET_YAML\n",
        "                              )\n",
        "\n",
        "    counts = prep.count_all()\n",
        "\n",
        "    for split, classes in counts.items():\n",
        "        print(f\"\\n{split.upper()}\")\n",
        "\n",
        "        for cls, n in classes.items():\n",
        "            print(f\"{cls}: {n}\")\n",
        "\n",
        "    prep.classes_show()\n",
        "\n",
        "    prep.plot_class_examples()\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Iy9to1SMkihn"
      },
      "source": [
        "# ModelYoloV8"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "silQqEwGpOTI"
      },
      "source": [
        "## Install ultralytics library"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LMub2hKTma4o",
        "outputId": "d4997af1-f661-47ca-8c08-d3e47c3eab22"
      },
      "outputs": [],
      "source": [
        "!pip install -q ultralytics\n",
        "!pip install -q optuna"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XwahH2lbpV87"
      },
      "source": [
        "## yolov8_module"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "G95KLszJmEGg"
      },
      "outputs": [],
      "source": [
        "# Imports\n",
        "from ultralytics import YOLO\n",
        "import shutil\n",
        "from pathlib import Path\n",
        "\n",
        "# Classes\n",
        "class ModelYoloV8():\n",
        "    \"\"\"\n",
        "    Wrapper class for training, evaluating, and saving YOLOv8 models.\n",
        "\n",
        "    This class provides a thin abstraction over the Ultralytics YOLO API,\n",
        "    exposing common workflows such as training, validation, metric extraction,\n",
        "    and saving the best model weights.\n",
        "    \"\"\"\n",
        "\n",
        "    # Atributes\n",
        "    def __init__(self, model_name: str = MODEL_NAME_YOLO):\n",
        "        \"\"\"\n",
        "        Initialize a YOLOv8 model.\n",
        "\n",
        "        Parameters\n",
        "        ----------\n",
        "        model_name : str, optional\n",
        "            Name or path of the YOLOv8 model to load (e.g., 'yolov8n.pt',\n",
        "            'yolov8m.pt'). Defaults to MODEL_NAME_YOLO.\n",
        "        \"\"\"\n",
        "\n",
        "        self.model = YOLO(model_name)\n",
        "        self.model_name = model_name\n",
        "        self.metrics = None\n",
        "\n",
        "\n",
        "    # Methods\n",
        "    def fit(self, **kwargs):\n",
        "        \"\"\"\n",
        "        Train the YOLOv8 model.\n",
        "\n",
        "        This method is a direct wrapper around ``YOLO.train`` and forwards\n",
        "        all keyword arguments to the underlying Ultralytics API.\n",
        "\n",
        "        Parameters\n",
        "        ----------\n",
        "        **kwargs\n",
        "            Keyword arguments supported by ``YOLO.train`` (e.g., data, epochs,\n",
        "            imgsz, batch, device, optimizer).\n",
        "\n",
        "        Returns\n",
        "        -------\n",
        "        object\n",
        "            Training results object returned by ``YOLO.train``.\n",
        "        \"\"\"\n",
        "\n",
        "        return self.model.train(**kwargs)\n",
        "\n",
        "    def evaluate(self, **kwargs):\n",
        "        \"\"\"\n",
        "        Evaluate the YOLOv8 model on a validation or test dataset.\n",
        "\n",
        "        This method runs model validation and extracts the most common\n",
        "        detection metrics related to bounding boxes.\n",
        "\n",
        "        Parameters\n",
        "        ----------\n",
        "        **kwargs\n",
        "            Keyword arguments supported by ``YOLO.val`` (e.g., data, split,\n",
        "            imgsz, device).\n",
        "\n",
        "        Returns\n",
        "        -------\n",
        "        dict\n",
        "            Dictionary containing evaluation metrics:\n",
        "            - 'map50_95': mean Average Precision at IoU 0.50:0.95\n",
        "            - 'map50'   : mean Average Precision at IoU 0.50\n",
        "            - 'map75'   : mean Average Precision at IoU 0.75\n",
        "            - 'per_class_map': per-class mAP values\n",
        "\n",
        "        Raises\n",
        "        ------\n",
        "        ValueError\n",
        "            If evaluation fails or expected metrics are unavailable.\n",
        "        \"\"\"\n",
        "\n",
        "        self.metrics = self.model.val(**kwargs)\n",
        "\n",
        "        if self.metrics is None or not hasattr(self.metrics, \"box\"):\n",
        "            raise ValueError(\"Evaluation failed or metrics are unavailable.\")\n",
        "\n",
        "        return {\n",
        "                \"map50_95\": self.metrics.box.map,\n",
        "                \"map50\": self.metrics.box.map50,\n",
        "                \"map75\": self.metrics.box.map75,\n",
        "                \"per_class_map\": self.metrics.box.maps\n",
        "                }\n",
        "\n",
        "    def save_model(self, weight_name_model):\n",
        "        \"\"\"\n",
        "        Save the best model weights after training.\n",
        "\n",
        "        This method copies the best-performing weights (as determined during\n",
        "        training) to a user-defined location.\n",
        "\n",
        "        Parameters\n",
        "        ----------\n",
        "        weight_name_model : str\n",
        "            Filename (or relative path) to store the best model weights.\n",
        "\n",
        "        Raises\n",
        "        ------\n",
        "        ValueError\n",
        "            If training has not been completed or best weights are unavailable.\n",
        "        \"\"\"\n",
        "\n",
        "        if self.model.trainer is None or self.model.trainer.best is None:\n",
        "            raise ValueError(\"Model training has not been completed or 'best' weights are unavailable.\")\n",
        "\n",
        "        best = self.model.trainer.best\n",
        "        shutil.copy(best, ROOT_DIR / weight_name_model)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1LonzUUERP1h"
      },
      "source": [
        "## tuning_optimizer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4vOF9RC6RWRX"
      },
      "outputs": [],
      "source": [
        "# Imports\n",
        "import torch\n",
        "import random\n",
        "import numpy as np\n",
        "import gc\n",
        "\n",
        "def set_seed(seed=42):\n",
        "    \"\"\"\n",
        "    Set random seeds for reproducibility.\n",
        "\n",
        "    This function fixes the random state for Python's built-in random module,\n",
        "    NumPy, and PyTorch to ensure deterministic behavior across runs.\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    seed : int, optional\n",
        "        Random seed value used to initialize all random number generators.\n",
        "        Defaults to 42.\n",
        "    \"\"\"\n",
        "\n",
        "    random.seed(seed)\n",
        "    np.random.seed(seed)\n",
        "    torch.manual_seed(seed)\n",
        "\n",
        "def objective(trial):\n",
        "    \"\"\"\n",
        "    Optuna objective function for YOLOv8 hyperparameter optimization.\n",
        "\n",
        "    This function defines the search space, trains a YOLOv8 model using\n",
        "    the sampled hyperparameters, evaluates it on the validation split,\n",
        "    and returns the optimization metric.\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    trial : optuna.trial.Trial\n",
        "        Optuna trial object used to sample hyperparameters.\n",
        "\n",
        "    Returns\n",
        "    -------\n",
        "    float\n",
        "        Validation mAP (IoU 0.50:0.95) used as the optimization objective.\n",
        "    \"\"\"\n",
        "\n",
        "    set_seed()\n",
        "\n",
        "    params = {\n",
        "              \"lr0\": trial.suggest_float(\"lr0\", 1e-4, 1e-2, log=True),\n",
        "              \"lrf\": trial.suggest_float(\"lrf\", 0.01, 0.2),\n",
        "              \"weight_decay\": trial.suggest_float(\"weight_decay\", 1e-5, 1e-3, log=True),\n",
        "              \"box\": trial.suggest_float(\"box\", 7., 10.0),\n",
        "              \"cls\": trial.suggest_float(\"cls\", 0.4, 0.9),\n",
        "              \"dfl\": trial.suggest_float(\"dfl\", 1.4, 2.0),\n",
        "              \"iou\": trial.suggest_float(\"iou\", 0.4, 0.7),\n",
        "              }\n",
        "\n",
        "    model = ModelYoloV8(MODEL_NAME_YOLO)\n",
        "\n",
        "    model.fit(\n",
        "              data=DATASET_YAML,\n",
        "              device=DEVICE,\n",
        "              name=f\"optuna_trial_{trial.number}\",\n",
        "              project=\"runs/optuna\",\n",
        "              imgsz=640,\n",
        "\n",
        "              epochs=8,\n",
        "              patience=2,\n",
        "              batch=32,\n",
        "\n",
        "              freeze=8,\n",
        "\n",
        "              optimizer=\"AdamW\",\n",
        "              warmup_epochs=2,\n",
        "              warmup_bias_lr=0.1,\n",
        "              momentum = 0.937,\n",
        "\n",
        "              verbose=False,\n",
        "              **params\n",
        "              )\n",
        "\n",
        "    model.evaluate(\n",
        "                   data=DATASET_YAML,\n",
        "                   device=DEVICE,\n",
        "                   split=\"val\",\n",
        "                   )\n",
        "\n",
        "    value = model.metrics.box.map  # type: ignore\n",
        "\n",
        "    del model\n",
        "    gc.collect()\n",
        "    torch.cuda.empty_cache()\n",
        "    return value\n",
        "\n",
        "\n",
        "def load_best_params(csv_path):\n",
        "    \"\"\"\n",
        "    Load the best hyperparameters from an Optuna trials CSV file.\n",
        "\n",
        "    This function filters completed trials, selects the one with the\n",
        "    highest objective value, and extracts the corresponding parameters.\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    csv_path : str or pathlib.Path\n",
        "        Path to the CSV file exported by Optuna containing trial results.\n",
        "\n",
        "    Returns\n",
        "    -------\n",
        "    dict\n",
        "        Dictionary containing the best hyperparameters, ready to be passed\n",
        "        to a YOLOv8 training configuration.\n",
        "    \"\"\"\n",
        "\n",
        "    df = pd.read_csv(csv_path)\n",
        "\n",
        "    # Best trial\n",
        "    df = df[df[\"state\"] == \"COMPLETE\"]\n",
        "    best_row = df.sort_values(\"value\", ascending=False).iloc[0]\n",
        "\n",
        "    # Best Params\n",
        "    best_params = {\n",
        "                   \"lr0\":          float(best_row[\"params_lr0\"]),\n",
        "                   \"lrf\":          float(best_row[\"params_lrf\"]),\n",
        "                   \"weight_decay\": float(best_row[\"params_weight_decay\"]),\n",
        "                   \"box\":          float(best_row[\"params_box\"]),\n",
        "                   \"cls\":          float(best_row[\"params_cls\"]),\n",
        "                   \"dfl\":          float(best_row[\"params_dfl\"]),\n",
        "                   \"iou\":          float(best_row[\"params_iou\"]),\n",
        "                   }\n",
        "\n",
        "    return best_params"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1_1LJCdIpfkK"
      },
      "source": [
        "## YoloModelV8 train_baseline"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QSLIJ_WQpkPA",
        "outputId": "08b84fbc-ac30-4de9-8b59-cd4fd2b69768"
      },
      "outputs": [],
      "source": [
        "%%time\n",
        "\n",
        "def main():\n",
        "    \"\"\"\n",
        "    Baseline training and evaluation script for YOLOv8.\n",
        "\n",
        "    This script trains a YOLOv8 model for marine debris detection using a\n",
        "    fixed baseline configuration, evaluates the trained model on the test\n",
        "    split, and saves the best-performing weights to disk.\n",
        "    \"\"\"\n",
        "\n",
        "    model_yolov8 = ModelYoloV8()  # 640x640 Size\n",
        "\n",
        "    # Training\n",
        "    trained_yolov8 = model_yolov8.fit(\n",
        "                                      data=DATASET_YAML,\n",
        "                                      device=DEVICE,\n",
        "                                      name=\"baseline\",\n",
        "                                      project=\"runs/baseline\",\n",
        "                                      imgsz=640,\n",
        "\n",
        "                                      batch=32,\n",
        "                                      epochs=30,\n",
        "                                      patience=5,\n",
        "                                      freeze=8,  # 10 -> last block layers of the backbone\n",
        "\n",
        "                                      # Optimizer\n",
        "                                      optimizer=\"AdamW\",\n",
        "                                      warmup_epochs = 5,\n",
        "                                      warmup_bias_lr=0.1,\n",
        "                                      momentum = 0.937,\n",
        "\n",
        "                                      # IOU: The smaller the number, the lower the chance of overlap.\n",
        "                                      iou = 0.5,  # default = 0.7,\n",
        "\n",
        "                                      weight_decay = 0.0005,\n",
        "                                      lr0 = 0.003,\n",
        "                                      lrf = 0.01,  # lr_final = lr0 * lrf\n",
        "\n",
        "                                      # Losses\n",
        "                                      box = 10.,  # default = 7.5\n",
        "                                      cls = 0.8,  # default = 0.5\n",
        "                                      dfl = 2.,   # default = 1.5\n",
        "                                      )\n",
        "\n",
        "    # Test Metrics\n",
        "    print(\"\\n\" * 5)\n",
        "    print(f\"TEST METRICS\")\n",
        "    metrics_yolov8 = model_yolov8.evaluate(\n",
        "                                           data=DATASET_YAML,\n",
        "                                           device=DEVICE,\n",
        "                                           split=\"test\"\n",
        "                                           )\n",
        "    print(metrics_yolov8)\n",
        "\n",
        "    # Saving model in memory\n",
        "    model_yolov8.save_model(weight_name_model=\"yolov8n_marinedebris_baseline.pt\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7bhgRNr_WOAx"
      },
      "source": [
        "## YoloModelV8 tune"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G8QbZEa5WVf5",
        "outputId": "e2b7f2e3-fe6c-482d-8506-3b3e6ae18553"
      },
      "outputs": [],
      "source": [
        "%%time\n",
        "\n",
        "# Imports\n",
        "import optuna\n",
        "\n",
        "# Main\n",
        "def main():\n",
        "    \"\"\"\n",
        "    Run the Optuna optimization pipeline for YOLOv8.\n",
        "\n",
        "    This function creates an Optuna study, executes hyperparameter\n",
        "    optimization, reports the best trial, and saves all trial results\n",
        "    to disk.\n",
        "    \"\"\"\n",
        "\n",
        "    study = optuna.create_study(\n",
        "                                direction=\"maximize\",\n",
        "                                study_name=\"yolov8_marine_debris\"\n",
        "                                )\n",
        "\n",
        "    study.optimize(\n",
        "                   objective,\n",
        "                   n_trials=20,\n",
        "                   timeout=None\n",
        "                   )\n",
        "\n",
        "    # Metrics\n",
        "    print(\"Best trial:\")\n",
        "    print(\"  Value:\", study.best_value)\n",
        "    print(\"  Params:\")\n",
        "    for k, v in study.best_params.items():\n",
        "        print(f\"    {k}: {v}\")\n",
        "\n",
        "    study.trials_dataframe().to_csv(OPTIMIZER_RESULTS, index=False)\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ud-1C60nXZBE"
      },
      "source": [
        "## YoloModelV8 train_final_fase1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6s9dYVWNXvFy",
        "outputId": "0fba4b20-e383-48b5-ffc9-defcdeaa4643"
      },
      "outputs": [],
      "source": [
        "%%time\n",
        "\n",
        "def main():\n",
        "    \"\"\"\n",
        "    Final training and evaluation script for YOLOv8 using Optuna-selected parameters.\n",
        "\n",
        "    This script loads the best hyperparameters obtained from Optuna optimization,\n",
        "    trains a final YOLOv8 model on the full training setup, evaluates it on the\n",
        "    test dataset, and saves both the trained weights and the parameters used.\n",
        "    \"\"\"\n",
        "\n",
        "    best_params = load_best_params(OPTIMIZER_RESULTS)\n",
        "    print(best_params)\n",
        "\n",
        "    model = ModelYoloV8(MODEL_NAME_YOLO)\n",
        "\n",
        "    # Final Train\n",
        "    model.fit(\n",
        "              data=DATASET_YAML,\n",
        "              device=DEVICE,\n",
        "              imgsz=640,\n",
        "\n",
        "              batch=32,\n",
        "              epochs=50,\n",
        "              patience=5,\n",
        "\n",
        "              freeze=8,\n",
        "\n",
        "              optimizer=\"AdamW\",\n",
        "              warmup_epochs=5,\n",
        "              warmup_bias_lr=0.1,\n",
        "              momentum=0.937,\n",
        "\n",
        "              **best_params\n",
        "              )\n",
        "\n",
        "    metrics = model.evaluate(\n",
        "                             data=DATASET_YAML,\n",
        "                             device=DEVICE,\n",
        "                             split=\"test\"\n",
        "                             )\n",
        "\n",
        "    print(\"FINAL TEST METRICS:\", metrics)\n",
        "\n",
        "    model.save_model(weight_name_model=\"yolov8n_marinedebris_best_final_1.pt\")\n",
        "    pd.Series(best_params).to_csv(ROOT_DIR / \"best_params_used_final_model_1.csv\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vVD5wgo6lQ8G"
      },
      "source": [
        "## YoloModelV8 train_baseline_adjusted"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7VRF00zClZPr",
        "outputId": "74ca2678-1b6f-4c37-de94-2f4fb9d88576"
      },
      "outputs": [],
      "source": [
        "%%time\n",
        "\n",
        "def main():\n",
        "    model_yolov8 = ModelYoloV8()  # 640x640 Size\n",
        "\n",
        "    # Training\n",
        "    trained_yolov8 = model_yolov8.fit(\n",
        "                                      data=DATASET_YAML,\n",
        "                                      device=DEVICE,\n",
        "                                      name=\"baseline_adjusted\",\n",
        "                                      project=\"runs/baseline_adjusted\",\n",
        "                                      imgsz=640,\n",
        "\n",
        "                                      batch=32,\n",
        "                                      epochs=30,\n",
        "                                      patience=5,\n",
        "                                      freeze=8,  # 10 -> last block layers of the backbone\n",
        "\n",
        "                                      # Optimizer\n",
        "                                      optimizer=\"AdamW\",\n",
        "                                      warmup_epochs = 5,\n",
        "                                      warmup_bias_lr=0.1,\n",
        "                                      momentum = 0.937,\n",
        "\n",
        "                                      # IOU: The smaller the number, the lower the chance of overlap.\n",
        "                                      iou = 0.6,  # default = 0.7,\n",
        "\n",
        "                                      weight_decay = 0.0005,\n",
        "                                      lr0 = 0.003,\n",
        "                                      lrf = 0.01,  # lr_final = lr0 * lrf\n",
        "\n",
        "                                      # Losses\n",
        "                                      box = 10.,  # default = 7.5\n",
        "                                      cls = 0.6,  # default = 0.5\n",
        "                                      dfl = 2.,   # default = 1.5\n",
        "                                      )\n",
        "\n",
        "    # Test Metrics\n",
        "    print(\"\\n\" * 5)\n",
        "    print(f\"TEST METRICS\")\n",
        "    metrics_yolov8 = model_yolov8.evaluate(\n",
        "                                           data=DATASET_YAML,\n",
        "                                           device=DEVICE,\n",
        "                                           split=\"test\",\n",
        "                                           agnostic_nms=True\n",
        "                                           )\n",
        "    print(metrics_yolov8)\n",
        "\n",
        "    # Confusion Matrix\n",
        "    cm = model_yolov8.metrics.confusion_matrix.matrix\n",
        "    sns.heatmap(cm, annot=True, fmt=\"d\")\n",
        "    plt.xlabel(\"Predicted\")\n",
        "    plt.ylabel(\"True\")\n",
        "    plt.show()\n",
        "\n",
        "    # Saving model in memory\n",
        "    model_yolov8.save_model(weight_name_model=\"yolov8n_marinedebris_baseline_adjusted.pt\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l9Rast_Xi94C"
      },
      "source": [
        "## YoloModelV8 train_final_fase2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xIiBf1P9jFZR"
      },
      "outputs": [],
      "source": [
        "%%time\n",
        "\n",
        "def main():\n",
        "    best_params = load_best_params(OPTIMIZER_RESULTS)\n",
        "    print(best_params)\n",
        "\n",
        "    model = ModelYoloV8(MODEL_NAME_YOLO_FINAL1)\n",
        "\n",
        "    # New Fine-tuning\n",
        "    model.fit(\n",
        "              data=DATASET_YAML,\n",
        "              device=DEVICE,\n",
        "              imgsz=640,\n",
        "              batch=16,\n",
        "              epochs=20,\n",
        "              patience=5,\n",
        "              freeze=0,\n",
        "              lr0=best_params[\"lr0\"] * 0.1\n",
        "              )\n",
        "\n",
        "    metrics = model.evaluate(\n",
        "                             data=DATASET_YAML,\n",
        "                             device=DEVICE,\n",
        "                             split=\"test\"\n",
        "                             )\n",
        "\n",
        "    # Confusion Matrix\n",
        "    cm = metrics.confusion_matrix.metrics\n",
        "    sns.heatmap(cm, annot=True, fmt=\"d\")\n",
        "    plt.xlabel(\"Predicted\")\n",
        "    plt.ylabel(\"True\")\n",
        "    plt.show()\n",
        "\n",
        "    print(\"FINAL TEST METRICS:\", metrics)\n",
        "\n",
        "    model.save_model(weight_name_model=MODEL_NAME_YOLO_FINAL_TUNNED)\n",
        "    pd.Series(best_params).to_csv(MODEL_NAME_YOLO_FINAL_PARAMS)\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eAYqCw37q7-T"
      },
      "source": [
        "## YoloModelV8 train_final_baseline_tunned"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "regwr_HPrCO8",
        "outputId": "f7406dd8-cb7f-42bf-fc07-bfb554d6dca1"
      },
      "outputs": [],
      "source": [
        "%%time\n",
        "import seaborn as sns\n",
        "\n",
        "def main():\n",
        "    \"\"\"\n",
        "    Fine-tuning and evaluation script for a YOLOv8 baseline model.\n",
        "\n",
        "    This script fine-tunes the previous trained YOLOv8 baseline model version in \"train_baseline.py\"\n",
        "    using a reduced learning rate, evaluates performance on the test dataset, visualizes the\n",
        "    confusion matrix, and saves the tuned model weights.\n",
        "    \"\"\"\n",
        "\n",
        "    model = ModelYoloV8(WEIGHTS_YOLOV8_BASELINE)\n",
        "\n",
        "    # Fine-tuning\n",
        "    model.fit(\n",
        "              data=DATASET_YAML,\n",
        "              device=DEVICE,\n",
        "              imgsz=640,\n",
        "              batch=16,\n",
        "              epochs=20,\n",
        "              patience=5,\n",
        "              freeze=0,\n",
        "              lr0=0.003 * 0.1\n",
        "              )\n",
        "\n",
        "    metrics = model.evaluate(\n",
        "                             data=DATASET_YAML,\n",
        "                             device=DEVICE,\n",
        "                             split=\"test\"\n",
        "                             )\n",
        "\n",
        "    # Confusion Matrix\n",
        "    cm = model.metrics.confusion_matrix.matrix.astype(int)\n",
        "    sns.heatmap(\n",
        "                cm,\n",
        "                annot=True,\n",
        "                fmt=\"d\",\n",
        "                cmap=\"Greens\",\n",
        "                cbar=True,\n",
        "                linewidths=0.5,\n",
        "                linecolor=\"white\"\n",
        "                )\n",
        "\n",
        "    plt.xlabel(\"Predicted\")\n",
        "    plt.ylabel(\"True\")\n",
        "    plt.title(\"Confusion Matrix (Counts)\")\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "    print(\"FINAL TEST METRICS:\", metrics)\n",
        "\n",
        "    model.save_model(weight_name_model=MODEL_NAME_YOLO_FINAL_BASELINE_TUNNED)\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VTXVCsHtkmWM"
      },
      "source": [
        "# PredictionInference YOLOV8"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S8jGCw61I1wf"
      },
      "source": [
        "## inference.py"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mbcDdR68OFZn",
        "outputId": "f0f1b3c6-92d2-4d6a-f5f3-f2b022d97d93"
      },
      "outputs": [],
      "source": [
        "#!pip -q install norfair\n",
        "!pip install -q --force-reinstall \"numpy<2.0\" \"scipy<1.12\" norfair"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "collapsed": true,
        "id": "lf-YPlhiFxcB",
        "outputId": "7a7eeeee-a2ce-4c61-ba34-eba3e22f3a1e"
      },
      "outputs": [],
      "source": [
        "!pip uninstall -y numpy scipy norfair\n",
        "!pip install numpy==1.26.4\n",
        "!pip install scipy==1.11.4\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "8e1Qe7eJGH3G",
        "outputId": "34559701-8fb4-4bb2-e821-b664efe6c467"
      },
      "outputs": [],
      "source": [
        "!pip install norfair"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "igsZdkylI4mb"
      },
      "outputs": [],
      "source": [
        "import cv2\n",
        "import matplotlib.pyplot as plt\n",
        "from google.colab.patches import cv2_imshow\n",
        "from ultralytics import YOLO\n",
        "import numpy as np\n",
        "from norfair import Detection, Tracker, Video, draw_tracked_objects\n",
        "\n",
        "CLASS_COLORS = {\n",
        "                \"can\": (255, 0, 0),               # blue\n",
        "                \"foam\": (0, 255, 255),            # yellow\n",
        "                \"plastic\": (0, 255, 0),           # green\n",
        "                \"plastic bottle\": (0, 165, 255),  # orange\n",
        "                \"unknow\": (128, 128, 128),        # gray\n",
        "                }\n",
        "\n",
        "class InferencePicture():\n",
        "    \"\"\"\n",
        "    Perform YOLOv8 inference on a single image and visualize detections.\n",
        "\n",
        "    This class loads a YOLOv8 model with specified weights, runs inference\n",
        "    on a given image, renders the detected bounding boxes, and displays\n",
        "    the resulting image.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, weights_yolo, image_path):\n",
        "        \"\"\"\n",
        "        Initialize the image inference pipeline.\n",
        "\n",
        "        Parameters\n",
        "        ----------\n",
        "        weights_yolo : str or pathlib.Path\n",
        "            Path to the YOLOv8 model weights file.\n",
        "        image_path : str or pathlib.Path\n",
        "            Path to the input image used for inference.\n",
        "        \"\"\"\n",
        "\n",
        "        self.model = YOLO(weights_yolo)\n",
        "        self.image_path = image_path\n",
        "\n",
        "    def results(self):\n",
        "        \"\"\"\n",
        "        Run inference on the input image and display detections.\n",
        "\n",
        "        This method performs YOLOv8 prediction, draws bounding boxes\n",
        "        on the image, displays the result using matplotlib, and\n",
        "        returns the raw YOLO results object.\n",
        "\n",
        "        Returns\n",
        "        -------\n",
        "        list\n",
        "            List of YOLOv8 Results objects containing detection outputs.\n",
        "        \"\"\"\n",
        "\n",
        "        results = self.model.predict(\n",
        "                                     source=self.image_path,\n",
        "                                     imgsz=640,\n",
        "                                     agnostic_nms=True\n",
        "                                     )\n",
        "        img_det = results[0].plot()\n",
        "        img_det = img_det[:, :, ::-1]\n",
        "\n",
        "        h, w = img_det.shape[:2]\n",
        "        dpi = 100\n",
        "\n",
        "        plt.figure(figsize=(w / dpi, h / dpi), dpi=dpi)\n",
        "        plt.imshow(img_det)\n",
        "        plt.axis(\"off\")\n",
        "        plt.show()\n",
        "\n",
        "        return results\n",
        "\n",
        "class InferenceVideo():\n",
        "    \"\"\"\n",
        "    Perform object detection and tracking on a video using a YOLO model.\n",
        "\n",
        "    This class loads a trained YOLO model, iterates over video frames,\n",
        "    performs inference, tracks detected objects across frames, and\n",
        "    renders bounding boxes with object IDs, class labels, and confidence\n",
        "    scores on the output video.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, input_path: str, model_path):\n",
        "        \"\"\"\n",
        "        Initialize the video inference pipeline.\n",
        "\n",
        "        Parameters\n",
        "        ----------\n",
        "        input_path : str\n",
        "            Path to the input video file.\n",
        "        model_path : str\n",
        "            Path to the trained YOLO model weights.\n",
        "        \"\"\"\n",
        "\n",
        "        self.input_path = input_path\n",
        "        self.model = YOLO(model_path)\n",
        "        self.video = Video(input_path=self.input_path)\n",
        "        self.tracker = Tracker(distance_function=\"euclidean\", distance_threshold=100)\n",
        "\n",
        "    def run(self):\n",
        "        \"\"\"\n",
        "        Run inference and tracking over the entire video.\n",
        "\n",
        "        For each frame, the method:\n",
        "        - Runs YOLO inference to detect objects.\n",
        "        - Converts detections into tracking-compatible format.\n",
        "        - Updates object tracks using a distance-based tracker.\n",
        "        - Draws bounding boxes, object IDs, class names, and confidence\n",
        "          scores on the frame.\n",
        "        - Writes the processed frame to the output video.\n",
        "        \"\"\"\n",
        "\n",
        "        for frame in self.video:\n",
        "            results = self.model(frame, agnostic_nms=True, conf=0.4)  # Inference\n",
        "            detections = []\n",
        "\n",
        "            for r in results:\n",
        "                boxes = r.boxes\n",
        "                if boxes is None or len(boxes) == 0:\n",
        "                    continue\n",
        "\n",
        "                for xyxy, cls_id, conf in zip(boxes.xyxy, boxes.cls, boxes.conf):\n",
        "                    x1, y1, x2, y2 = xyxy.tolist()\n",
        "\n",
        "                    # Center for tracking\n",
        "                    center = np.array([(x1 + x2) / 2, (y1 + y2) / 2], dtype=np.float32)\n",
        "\n",
        "                    detections.append(\n",
        "                                    Detection(\n",
        "                                                points=center,\n",
        "                                                scores=np.array([float(conf)]),\n",
        "                                                data={\n",
        "                                                    \"bbox\": (int(x1), int(y1), int(x2), int(y2)),\n",
        "                                                    \"class_name\": self.model.names[int(cls_id)],\n",
        "                                                    \"conf\": float(conf),\n",
        "                                                    },\n",
        "                                                )\n",
        "                                    )\n",
        "\n",
        "            tracked_objects = self.tracker.update(detections=detections)\n",
        "\n",
        "            # Drawing bounding boxes\n",
        "            for obj in tracked_objects:\n",
        "                det = obj.last_detection\n",
        "                if det is None or det.data is None:\n",
        "                    continue\n",
        "\n",
        "                x1, y1, x2, y2 = det.data[\"bbox\"]\n",
        "                label = det.data[\"class_name\"]\n",
        "                conf = det.data[\"conf\"]\n",
        "\n",
        "                color = CLASS_COLORS.get(label, (255, 255, 255))\n",
        "\n",
        "                cv2.rectangle(frame, (x1, y1), (x2, y2), color, 2)\n",
        "                cv2.putText(\n",
        "                            frame,\n",
        "                            f\"ID {obj.id} | {label} {conf:.2f}\",\n",
        "                            (x1, max(0, y1 - 8)),\n",
        "                            cv2.FONT_HERSHEY_SIMPLEX,\n",
        "                            0.55,\n",
        "                            color,\n",
        "                            2,\n",
        "                            cv2.LINE_AA,\n",
        "                            )\n",
        "\n",
        "            self.video.write(frame)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VWB1WQh4HidZ"
      },
      "outputs": [],
      "source": [
        "from pathlib import Path\n",
        "import cv2\n",
        "from ultralytics import YOLO  # type: ignore\n",
        "import numpy as np\n",
        "from norfair import Detection, Tracker  # type: ignore\n",
        "\n",
        "CLASS_COLORS = {\n",
        "                \"can\": (255, 0, 0),               # blue\n",
        "                \"foam\": (0, 255, 255),            # yellow\n",
        "                \"plastic\": (0, 255, 0),           # green\n",
        "                \"plastic bottle\": (0, 165, 255),  # orange\n",
        "                \"unknow\": (128, 128, 128),        # gray\n",
        "                }\n",
        "\n",
        "class InferencePicture():\n",
        "    \"\"\"\n",
        "    Perform YOLOv8 inference on a single image.\n",
        "\n",
        "    This class runs object detection on an input image and returns\n",
        "    the annotated image as a NumPy array, suitable for API responses\n",
        "    or further processing.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, weights_yolo, image_path):\n",
        "        \"\"\"\n",
        "        Initialize the image inference pipeline.\n",
        "\n",
        "        Parameters\n",
        "        ----------\n",
        "        weights_yolo : str or pathlib.Path\n",
        "            Path to the YOLOv8 model weights file.\n",
        "        image_path : str or pathlib.Path\n",
        "            Path to the input image used for inference.\n",
        "        \"\"\"\n",
        "\n",
        "        self.model = YOLO(weights_yolo)\n",
        "        self.image_path = image_path\n",
        "\n",
        "    def run(self):\n",
        "        \"\"\"\n",
        "        Run YOLOv8 inference and return the annotated image.\n",
        "\n",
        "        Returns\n",
        "        -------\n",
        "        np.ndarray\n",
        "            Annotated image in RGB format (H, W, 3), dtype uint8.\n",
        "        \"\"\"\n",
        "\n",
        "        results = self.model.predict(\n",
        "                                     source=self.image_path,\n",
        "                                     imgsz=640,\n",
        "                                     agnostic_nms=True\n",
        "                                     )\n",
        "\n",
        "        img_bgr = results[0].plot()\n",
        "\n",
        "        return img_bgr\n",
        "\n",
        "class InferenceVideo():\n",
        "    \"\"\"\n",
        "    Perform object detection and tracking on a video using a YOLO model.\n",
        "\n",
        "    This class loads a trained YOLO model, iterates over video frames,\n",
        "    performs inference, tracks detected objects across frames, and\n",
        "    renders bounding boxes with object IDs, class labels, and confidence\n",
        "    scores on the output video.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, input_path: str, model_path):\n",
        "        \"\"\"\n",
        "        Initialize the video inference pipeline.\n",
        "\n",
        "        Parameters\n",
        "        ----------\n",
        "        input_path : str\n",
        "            Path to the input video file.\n",
        "        model_path : str\n",
        "            Path to the trained YOLO model weights.\n",
        "        \"\"\"\n",
        "\n",
        "        self.input_path = input_path\n",
        "        self.model = YOLO(model_path)\n",
        "        self.tracker = Tracker(distance_function=\"euclidean\", distance_threshold=100)\n",
        "\n",
        "\n",
        "    def run(self):\n",
        "        \"\"\"\n",
        "        Run inference and tracking over the entire video.\n",
        "\n",
        "        This version explicitly controls video reading and writing\n",
        "        using OpenCV to ensure compatibility in Docker environments.\n",
        "        \"\"\"\n",
        "\n",
        "        # OpenCV reader\n",
        "        cap = cv2.VideoCapture(self.input_path)\n",
        "        if not cap.isOpened():\n",
        "            raise RuntimeError(f\"Could not open video: {self.input_path}\")\n",
        "\n",
        "        fps = cap.get(cv2.CAP_PROP_FPS)\n",
        "\n",
        "        if not fps or fps <= 0:\n",
        "            fps = 30.0\n",
        "\n",
        "        width  = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
        "        height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
        "\n",
        "        # OpenCV writer\n",
        "        in_path = Path(self.input_path)\n",
        "        output_path = str(in_path.with_name(in_path.stem + \"_annotated.mp4\"))\n",
        "        fourcc = cv2.VideoWriter_fourcc(*\"mp4v\")  # type: ignore\n",
        "        writer = cv2.VideoWriter(output_path, fourcc, fps, (width, height))\n",
        "\n",
        "        # Frame loop\n",
        "        while True:\n",
        "            ret, frame = cap.read()\n",
        "            if not ret:\n",
        "                break\n",
        "\n",
        "            # YOLO inference\n",
        "            results = self.model(frame, agnostic_nms=True, conf=0.4)\n",
        "            detections = []\n",
        "\n",
        "            for r in results:\n",
        "                boxes = r.boxes\n",
        "                if boxes is None or len(boxes) == 0:\n",
        "                    continue\n",
        "\n",
        "                for xyxy, cls_id, conf in zip(boxes.xyxy, boxes.cls, boxes.conf):\n",
        "                    x1, y1, x2, y2 = xyxy.tolist()\n",
        "\n",
        "                    center = np.array(\n",
        "                                      [(x1 + x2) / 2, (y1 + y2) / 2],\n",
        "                                      dtype=np.float32\n",
        "                                      )\n",
        "\n",
        "                    detections.append(\n",
        "                        Detection(\n",
        "                            points=center,\n",
        "                            scores=np.array([float(conf)]),\n",
        "                            data={\n",
        "                                  \"bbox\": (int(x1), int(y1), int(x2), int(y2)),\n",
        "                                  \"class_name\": self.model.names[int(cls_id)],\n",
        "                                  \"conf\": float(conf),\n",
        "                                  },\n",
        "                                  )\n",
        "                                      )\n",
        "\n",
        "            # Norfair tracking\n",
        "            tracked_objects = self.tracker.update(detections=detections)\n",
        "\n",
        "            # Drawing bounding boxes\n",
        "            for obj in tracked_objects:\n",
        "                det = obj.last_detection\n",
        "                if det is None or det.data is None:\n",
        "                    continue\n",
        "\n",
        "                x1, y1, x2, y2 = det.data[\"bbox\"]\n",
        "                label = det.data[\"class_name\"]\n",
        "                conf = det.data[\"conf\"]\n",
        "\n",
        "                color = CLASS_COLORS.get(label, (255, 255, 255))\n",
        "\n",
        "                cv2.rectangle(frame, (x1, y1), (x2, y2), color, 2)\n",
        "                cv2.putText(\n",
        "                            frame,\n",
        "                            f\"ID {obj.id} | {label} {conf:.2f}\",\n",
        "                            (x1, max(0, y1 - 8)),\n",
        "                            cv2.FONT_HERSHEY_SIMPLEX,\n",
        "                            0.55,\n",
        "                            color,\n",
        "                            2,\n",
        "                            cv2.LINE_AA,\n",
        "                            )\n",
        "\n",
        "            # writer\n",
        "            writer.write(frame)\n",
        "\n",
        "        # Cleanup\n",
        "        cap.release()\n",
        "        writer.release()\n",
        "\n",
        "        return output_path"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "collapsed": true,
        "id": "3uV4IvTDOMMy",
        "outputId": "07a8f0c6-eef9-4857-ca49-85da3f8c1783"
      },
      "outputs": [],
      "source": [
        "# For images\n",
        "path = f\"{str(ROOT_DIR)}/{MODEL_NAME_YOLO_FINAL_BASELINE_TUNNED}\"\n",
        "inference = InferencePicture(path, TEST_IMAGE6)\n",
        "inference.results()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "5lNXIQ9BV_O1",
        "outputId": "77a7c523-131a-4863-d03f-d936d59b839a"
      },
      "outputs": [],
      "source": [
        "# For videos\n",
        "path_model = f\"{ROOT_DIR}/{MODEL_NAME_YOLO_FINAL_BASELINE_TUNNED}\"\n",
        "video_infer = InferenceVideo(\n",
        "                             model_path=str(path_model),\n",
        "                             input_path=str(TEST_VIDEO),\n",
        "                             )\n",
        "\n",
        "video_infer.run()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "d896c56ea5454ecc9672023da7f1ab01",
            "b755fa7e7b284505a5e785ec03e02047"
          ]
        },
        "id": "tB8Od-4kWSPg",
        "outputId": "06515eec-6302-4849-a01d-19a2faa72eb4"
      },
      "outputs": [],
      "source": [
        "# Main inference\n",
        "def main():\n",
        "    path = TEST_VIDEO  # TEST_VIDEO or TEST_IMAGE6\n",
        "\n",
        "    if path.suffix.lower() in {\".jpg\", \".jpeg\", \".png\", \".bmp\"}:\n",
        "        # Image\n",
        "        InferencePicture(Path(ROOT_DIR / MODEL_NAME_YOLO_FINAL_BASELINE_TUNNED), path).results()\n",
        "\n",
        "    elif path.suffix.lower() in {\".mp4\", \".avi\", \".mov\", \".mkv\"}:\n",
        "        # Video\n",
        "        InferenceVideo(str(path), str(Path(ROOT_DIR / MODEL_NAME_YOLO_FINAL_BASELINE_TUNNED))).run()\n",
        "\n",
        "    else:\n",
        "        raise ValueError(f\"Invalid format: {path.suffix}\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 622
        },
        "id": "SJu1-KOAiYt6",
        "outputId": "b2c7565f-887a-4050-cbd5-ca16ce1579d3"
      },
      "outputs": [],
      "source": [
        "# Imports\n",
        "import cv2\n",
        "import matplotlib.pyplot as plt\n",
        "from google.colab.patches import cv2_imshow\n",
        "from ultralytics import YOLO\n",
        "\n",
        "#Inference YOLOV8\n",
        "model = YOLO(WEIGHTS_YOLOV8_BASELINE)\n",
        "\n",
        "results = model.predict(\n",
        "                        source=TEST_IMAGE6,\n",
        "                        agnostic_nms=True\n",
        "                        )\n",
        "\n",
        "img_det = results[0].plot()\n",
        "cv2_imshow(img_det)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OYY6Et89Tem_",
        "outputId": "7ab45e35-2a7c-41c8-93dd-2fe5f7d8f4e2"
      },
      "outputs": [],
      "source": [
        "#!pip -q install norfair\n",
        "!pip install -q --force-reinstall \"numpy<2.0\" \"scipy<1.12\" norfair"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 401,
          "referenced_widgets": [
            "b59d6e50a7dd43579bca5180cab4e460",
            "b9b8d21a744a45e9bc4e35538eac31b8"
          ]
        },
        "id": "sEP7pahOTg4n",
        "outputId": "ac7e3b5a-24b0-4155-ec45-aba4c9c52eb1"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "from norfair import Detection, Tracker, Video, draw_tracked_objects\n",
        "\n",
        "# Config Norfair\n",
        "video = Video(input_path=str(TEST_VIDEO))\n",
        "tracker = Tracker(distance_function=\"euclidean\", distance_threshold=150)\n",
        "model = YOLO(WEIGHTS_YOLOV8_BASELINE)\n",
        "\n",
        "for frame in video:\n",
        "    results = model(frame)  # Inference\n",
        "    detections = []\n",
        "\n",
        "    for result in results:\n",
        "        for box in result.boxes.xyxy:  # Bounding Boxes\n",
        "            x1, y1, x2, y2 = box.tolist()\n",
        "            center = np.array([(x1 + x2) / 2, (y1 + y2) / 2])\n",
        "            detections.append(Detection(center))\n",
        "\n",
        "    tracked_objects = tracker.update(detections=detections)\n",
        "    draw_tracked_objects(frame, tracked_objects)\n",
        "    video.write(frame)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "b85d3132bf81477ca26e7bb37f55afea",
            "69901348d998421b9ac6d3f7b603f985"
          ]
        },
        "id": "mhJ1dfna1kvC",
        "outputId": "6004fe52-13d7-4fd9-fea3-4dc9e8ccc667"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import cv2\n",
        "from norfair import Detection, Tracker, Video\n",
        "\n",
        "path = f\"{str(ROOT_DIR)}/{MODEL_NAME_YOLO_FINAL_BASELINE_TUNNED}\"\n",
        "model = YOLO(path)\n",
        "\n",
        "CLASS_COLORS = {\n",
        "                \"can\": (255, 0, 0),             # blue\n",
        "                \"foam\": (0, 255, 255),          # yellow\n",
        "                \"plastic\": (0, 255, 0),         # green\n",
        "                \"plastic bottle\": (0, 165, 255),# orange\n",
        "                \"unknow\": (128, 128, 128),      # gray\n",
        "                }\n",
        "\n",
        "video = Video(input_path=str(TEST_VIDEO))\n",
        "tracker = Tracker(distance_function=\"euclidean\", distance_threshold=80)\n",
        "\n",
        "for frame in video:\n",
        "    results = model(frame, agnostic_nms=True)\n",
        "    detections = []\n",
        "\n",
        "    for r in results:\n",
        "        boxes = r.boxes\n",
        "        if boxes is None or len(boxes) == 0:\n",
        "            continue\n",
        "\n",
        "        for xyxy, cls_id, conf in zip(boxes.xyxy, boxes.cls, boxes.conf):\n",
        "            x1, y1, x2, y2 = xyxy.tolist()\n",
        "\n",
        "            # Center for tracking\n",
        "            center = np.array([(x1 + x2) / 2, (y1 + y2) / 2], dtype=np.float32)\n",
        "\n",
        "            detections.append(\n",
        "                              Detection(\n",
        "                                        points=center,\n",
        "                                        scores=np.array([float(conf)]),\n",
        "                                        data={\n",
        "                                              \"bbox\": (int(x1), int(y1), int(x2), int(y2)),\n",
        "                                              \"class_name\": model.names[int(cls_id)],\n",
        "                                              \"conf\": float(conf),\n",
        "                                              },\n",
        "                                        )\n",
        "                              )\n",
        "\n",
        "    tracked_objects = tracker.update(detections=detections)\n",
        "\n",
        "    # Drawing bounding boxes\n",
        "    for obj in tracked_objects:\n",
        "        det = obj.last_detection\n",
        "        if det is None or det.data is None:\n",
        "            continue\n",
        "\n",
        "        x1, y1, x2, y2 = det.data[\"bbox\"]\n",
        "        label = det.data[\"class_name\"]\n",
        "        conf = det.data[\"conf\"]\n",
        "\n",
        "        color = CLASS_COLORS.get(label, (255, 255, 255))\n",
        "\n",
        "        cv2.rectangle(frame, (x1, y1), (x2, y2), color, 2)\n",
        "        cv2.putText(\n",
        "                    frame,\n",
        "                    f\"ID {obj.id} | {label} {conf:.2f}\",\n",
        "                    (x1, max(0, y1 - 8)),\n",
        "                    cv2.FONT_HERSHEY_SIMPLEX,\n",
        "                    0.55,\n",
        "                    color,\n",
        "                    2,\n",
        "                    cv2.LINE_AA,\n",
        "                    )\n",
        "\n",
        "    video.write(frame)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JJUREwa54gzW"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [
        "xsNmWeu2hDyg",
        "n8fvSVURhafl",
        "YqhCBWk8yu_3",
        "silQqEwGpOTI",
        "XwahH2lbpV87",
        "1LonzUUERP1h",
        "1_1LJCdIpfkK",
        "7bhgRNr_WOAx",
        "Ud-1C60nXZBE",
        "vVD5wgo6lQ8G",
        "l9Rast_Xi94C"
      ],
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "69901348d998421b9ac6d3f7b603f985": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b59d6e50a7dd43579bca5180cab4e460": {
          "model_module": "@jupyter-widgets/output",
          "model_module_version": "1.0.0",
          "model_name": "OutputModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/output",
            "_model_module_version": "1.0.0",
            "_model_name": "OutputModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/output",
            "_view_module_version": "1.0.0",
            "_view_name": "OutputView",
            "layout": "IPY_MODEL_b9b8d21a744a45e9bc4e35538eac31b8",
            "msg_id": "",
            "outputs": [
              {
                "data": {
                  "text/html": "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">marine-debris-polution.mp4 <span style=\"color: #3a3a3a; text-decoration-color: #3a3a3a\">━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━</span> <span style=\"color: #800080; text-decoration-color: #800080\">  0%</span> <span style=\"color: #008080; text-decoration-color: #008080\">-:--:--</span> <span style=\"color: #808000; text-decoration-color: #808000\">7.05fps</span>\n</pre>\n",
                  "text/plain": "marine-debris-polution.mp4 \u001b[38;5;237m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[35m  0%\u001b[0m \u001b[36m-:--:--\u001b[0m \u001b[33m7.05fps\u001b[0m\n"
                },
                "metadata": {},
                "output_type": "display_data"
              }
            ]
          }
        },
        "b755fa7e7b284505a5e785ec03e02047": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b85d3132bf81477ca26e7bb37f55afea": {
          "model_module": "@jupyter-widgets/output",
          "model_module_version": "1.0.0",
          "model_name": "OutputModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/output",
            "_model_module_version": "1.0.0",
            "_model_name": "OutputModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/output",
            "_view_module_version": "1.0.0",
            "_view_name": "OutputView",
            "layout": "IPY_MODEL_69901348d998421b9ac6d3f7b603f985",
            "msg_id": "",
            "outputs": [
              {
                "data": {
                  "text/html": "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">marine-debris-polution.mp4 <span style=\"color: #729c1f; text-decoration-color: #729c1f\">━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━</span> <span style=\"color: #800080; text-decoration-color: #800080\">100%</span> <span style=\"color: #008080; text-decoration-color: #008080\">0:00:00</span> <span style=\"color: #808000; text-decoration-color: #808000\">12.77fps</span>\n</pre>\n",
                  "text/plain": "marine-debris-polution.mp4 \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[35m100%\u001b[0m \u001b[36m0:00:00\u001b[0m \u001b[33m12.77fps\u001b[0m\n"
                },
                "metadata": {},
                "output_type": "display_data"
              }
            ]
          }
        },
        "b9b8d21a744a45e9bc4e35538eac31b8": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d896c56ea5454ecc9672023da7f1ab01": {
          "model_module": "@jupyter-widgets/output",
          "model_module_version": "1.0.0",
          "model_name": "OutputModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/output",
            "_model_module_version": "1.0.0",
            "_model_name": "OutputModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/output",
            "_view_module_version": "1.0.0",
            "_view_name": "OutputView",
            "layout": "IPY_MODEL_b755fa7e7b284505a5e785ec03e02047",
            "msg_id": "",
            "outputs": [
              {
                "data": {
                  "text/html": "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">marine-debris-polution.mp4 <span style=\"color: #729c1f; text-decoration-color: #729c1f\">━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━</span> <span style=\"color: #800080; text-decoration-color: #800080\">100%</span> <span style=\"color: #008080; text-decoration-color: #008080\">0:00:00</span> <span style=\"color: #808000; text-decoration-color: #808000\">16.40fps</span>\n</pre>\n",
                  "text/plain": "marine-debris-polution.mp4 \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[35m100%\u001b[0m \u001b[36m0:00:00\u001b[0m \u001b[33m16.40fps\u001b[0m\n"
                },
                "metadata": {},
                "output_type": "display_data"
              }
            ]
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
